{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skincancer HAM-dataset med Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_training = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardimporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms, models\n",
    "from torchvision.utils import make_grid\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "import time\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hantering av GPU och CPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = get_default_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### De båda nedanstående blocken används för att enkelt flytta till GPU: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl: \n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hjälpfunktioner för att spara och ladda:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anropas när följande variabler finns tillgängliga:\n",
    "# epochs, batchsz-{train, val}, learning_rate\n",
    "# Dessa krävs för funktionen \"create_filename\".\n",
    "\n",
    "def create_filename(filename):\n",
    "    global file_name\n",
    "    file_name = filename + \"_e\" + str(epochs) + \"_bsztr\" + str(batchsz_train) + \\\n",
    "            \"_bszval\" + str(batchsz_val) + \"_lr\" + str(f'{learning_rate:.0e}')\n",
    "    return file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pytorch.org/docs/master/notes/serialization.html\n",
    "\n",
    "def save_trained_model(modelname):\n",
    "    model_folder = \"trained_models\"\n",
    "    model_file_suffix = \".pt\"\n",
    "    create_filename(modelname) # spottar ur sig ett filnamn i variabeln \"file_name\"\n",
    "    \n",
    "    full_model_filename = model_folder + \"/\" + file_name + model_file_suffix\n",
    "    \n",
    "    torch.save(model.state_dict(), full_model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_trained_model(modelname):\n",
    "    model_folder = \"trained_models\"\n",
    "    model_file_suffix = \".pt\"\n",
    "    create_filename(modelname) # spottar ur sig ett filnamn i variabeln \"file_name\"\n",
    "    \n",
    "    full_model_filename = model_folder + \"/\" + file_name + model_file_suffix\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        model.load_state_dict(torch.load(full_model_filename))\n",
    "    else:\n",
    "        model.load_state_dict(torch.load(full_model_filename, map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_training_log(logname, do_validation = True):\n",
    "    log_folder = \"logs\"\n",
    "    log_filename = create_filename(logname)\n",
    "    log_file_suffix = \".csv\"\n",
    "    full_log_filename = log_folder + \"/\" + file_name + log_file_suffix\n",
    "        \n",
    "    global training_log\n",
    "        \n",
    "    # Speciell range nedan för att starta på epok 1 och ej 0:\n",
    "    if do_validation == True:\n",
    "        training_log = pd.DataFrame(data={\"epoch\": range(1, epochs + 1), \\\n",
    "                                              \"train_acc\": train_accuracy, \\\n",
    "                                              \"train_loss\": train_losses,  \\\n",
    "                                              \"val_acc\": val_accuracy, \\\n",
    "                                              \"val_loss\": val_losses})\n",
    "    \n",
    "        training_log.to_csv(full_log_filename, sep=',', index = False)\n",
    "    else:\n",
    "        training_log = pd.DataFrame(data={\"epoch\": range(1, epochs + 1), \\\n",
    "                                              \"train_acc\": train_accuracy, \\\n",
    "                                              \"train_loss\": train_losses})\n",
    "    \n",
    "        training_log.to_csv(full_log_filename, sep=',', index = False)\n",
    "    \n",
    "    return training_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_training_log(logname):\n",
    "    log_folder = \"logs\"\n",
    "    log_filename = create_filename(logname)\n",
    "    log_file_suffix = \".csv\"\n",
    "    full_log_filename = log_folder + \"/\" + file_name + log_file_suffix\n",
    "    \n",
    "    global training_log\n",
    "    training_log = pd.read_csv(full_log_filename)\n",
    "    return training_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definiera de olika mängderna för träning, validering och test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "learning_rate = 1e-4\n",
    "\n",
    "img_w = 224\n",
    "img_h = 224\n",
    "img_dim = 3\n",
    "\n",
    "batchsz_train = 2**2\n",
    "batchsz_val = 2**6\n",
    "batchsz_test = 2**6\n",
    "\n",
    "train_num_workers = 4\n",
    "test_val_num_workers = 4\n",
    "\n",
    "basepath = \"../../../ml/Datasets/skin-cancer-mnist-ham10000/images_per_label_splitted_sets/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definiera vilken augmentation som ska göras:\n",
    "train_data_transform = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(img_w),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "val_test_data_transform = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(img_w),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definiera de tre dataseten:\n",
    "skincancer_train_dataset = datasets.ImageFolder(root = basepath + 'train/',\n",
    "                                           transform = train_data_transform)\n",
    "\n",
    "skincancer_valid_dataset = datasets.ImageFolder(root = basepath + 'val/',\n",
    "                                           transform = val_test_data_transform)\n",
    "\n",
    "skincancer_test_dataset = datasets.ImageFolder(root = basepath + 'test/',\n",
    "                                              transform = val_test_data_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skapa loaders för de tre dataseten:\n",
    "train_loader = torch.utils.data.DataLoader(skincancer_train_dataset,\n",
    "                                             batch_size = batchsz_train, \n",
    "                                             shuffle = True,\n",
    "                                             pin_memory = True,\n",
    "                                             drop_last = True,\n",
    "                                             num_workers = train_num_workers)\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(skincancer_valid_dataset,\n",
    "                                             batch_size = batchsz_val, \n",
    "                                             shuffle = True,\n",
    "                                             num_workers = test_val_num_workers)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(skincancer_test_dataset,\n",
    "                                             batch_size = batchsz_test, \n",
    "                                             shuffle = False,\n",
    "                                             num_workers = test_val_num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skapa en weighted loader som hanterar obalansen mellan klasserna:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_targets = train_loader.dataset.targets\n",
    "# print(len(train_targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import WeightedRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test för att oversampla vissa klasser...\n",
    "# https://discuss.pytorch.org/t/how-to-implement-oversampling-in-cifar-10/16964/6\n",
    "\n",
    "train_targets = train_loader.dataset.targets\n",
    "class_count = np.unique(train_targets, return_counts=True)[1]\n",
    "#print(\"Antal bilder per klass = \", class_count, \"\\n\")\n",
    "\n",
    "# Testa att köra med 1 / sevenones för att se en obalanserad, vanlig, loader\n",
    "# och med 1 / class_count för att se hur det balanserade resultatet blir:\n",
    "\n",
    "# sevenones = np.ones(7)\n",
    "# weight = 1 / sevenones\n",
    "weight = 1. / class_count\n",
    "samples_weight = weight[train_targets]\n",
    "samples_weight = torch.from_numpy(samples_weight)\n",
    "\n",
    "# Replacement = True ger dragning med återläggning, vilket vi ska ha, \n",
    "# annars kommer de mindre klasserna \"ta slut\" i dragningen:\n",
    "sampler = WeightedRandomSampler(samples_weight, len(samples_weight), replacement=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skapa en ny dataloader baserad på \n",
    "# träningssetet som är viktad klassivs:\n",
    "\n",
    "# \"pin_memory=True\" gör att man flyttar data till GPU:n medan \n",
    "# vi kör träningen, vilket påskyndar arbetet radikalt, ffa\n",
    "# om vi har komplexa modeller.\n",
    "train_loader_weighted = DataLoader(skincancer_train_dataset, \n",
    "                                   batch_size = batchsz_train, \n",
    "                                   sampler = sampler, # kan ej ha shuffle = True med sampler!\n",
    "                                   pin_memory=True,\n",
    "                                   drop_last=True,\n",
    "                                   num_workers = train_num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definiera antalet klasser:\n",
    "\n",
    "number_of_classes = len(test_loader.dataset.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flytta *_loader till rätt device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DeviceDataLoader(train_loader, device)\n",
    "train_dl_weighted = DeviceDataLoader(train_loader_weighted, device)\n",
    "valid_dl = DeviceDataLoader(valid_loader, device)\n",
    "test_dl = DeviceDataLoader(test_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visa skillnader mellan oviktad och viktad loader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antal bilder per klass =  [ 228  359  769   80  779 4693   99] \n",
      "\n",
      "Batch 0, classes [1 3 6], count [1 1 2]\n",
      "Batch 1, classes [0 2 6], count [2 1 1]\n",
      "Batch 2, classes [0 3 4 6], count [1 1 1 1]\n",
      "Batch 3, classes [0 5 6], count [1 1 2]\n"
     ]
    }
   ],
   "source": [
    "print(\"Antal bilder per klass = \", class_count, \"\\n\")\n",
    "\n",
    "# Visa hur den drar samples från klasserna för fyra batcher:\n",
    "for batch_idx, (data, target) in enumerate(train_loader_weighted):\n",
    "    print('Batch {}, classes {}, count {}'.format(\n",
    "        batch_idx, *np.unique(target.numpy(), return_counts=True)))\n",
    "    if batch_idx == 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antal bilder per klass =  [ 228  359  769   80  779 4693   99] \n",
      "\n",
      "Batch 0, classes [0 1 5], count [1 1 2]\n",
      "Batch 1, classes [5], count [4]\n",
      "Batch 2, classes [5], count [4]\n",
      "Batch 3, classes [2 4 5], count [1 2 1]\n"
     ]
    }
   ],
   "source": [
    "print(\"Antal bilder per klass = \", class_count, \"\\n\")\n",
    "\n",
    "# Visa hur den drar samples från klasserna för fyra batcher:\n",
    "for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    print('Batch {}, classes {}, count {}'.format(\n",
    "        batch_idx, *np.unique(target.numpy(), return_counts=True)))\n",
    "    if batch_idx == 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(target) # ger en vektor med batchsz i storlek.\n",
    "\n",
    "# Kolla t.ex. hur många samples ur klass A som finns i sista batchen ovan:\n",
    "# A = 0\n",
    "# np.sum(target.numpy() == A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visa dimensionerna för en bild-tensor (batchsize, number of channels, width, height):\n",
    "# images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definiera en modell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/densenet201-c1103571.pth\" to /Users/johanthor/.cache/torch/checkpoints/densenet201-c1103571.pth\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "# Nedanstående två rader måste göras oavsett träning eller ej:\n",
    "\n",
    "model = models.densenet201(pretrained = True, progress = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DenseNet(\n",
      "  (features): Sequential(\n",
      "    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu0): ReLU(inplace=True)\n",
      "    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (denseblock1): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (transition1): _Transition(\n",
      "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (denseblock2): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer7): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer8): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer9): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer10): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer11): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer12): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (transition2): _Transition(\n",
      "      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (denseblock3): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer7): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer8): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer9): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer10): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer11): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer12): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer13): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer14): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer15): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer16): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer17): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer18): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer19): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer20): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer21): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer22): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer23): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer24): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer25): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer26): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(1056, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer27): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1088, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer28): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(1120, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer29): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(1152, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer30): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(1184, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer31): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(1216, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer32): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(1248, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer33): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(1280, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer34): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1312, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(1312, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer35): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(1344, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer36): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1376, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(1376, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer37): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1408, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(1408, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer38): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(1440, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer39): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1472, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(1472, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer40): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1504, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(1504, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer41): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(1536, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer42): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1568, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(1568, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer43): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(1600, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer44): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(1632, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer45): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1664, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(1664, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer46): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1696, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(1696, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer47): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(1728, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer48): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1760, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(1760, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (transition3): _Transition(\n",
      "      (norm): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv): Conv2d(1792, 896, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (denseblock4): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(1056, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer7): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1088, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer8): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(1120, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer9): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(1152, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer10): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(1184, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer11): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(1216, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer12): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(1248, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer13): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(1280, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer14): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1312, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(1312, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer15): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(1344, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer16): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1376, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(1376, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer17): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1408, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(1408, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer18): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(1440, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer19): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1472, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(1472, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer20): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1504, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(1504, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer21): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(1536, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer22): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1568, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(1568, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer23): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(1600, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer24): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(1632, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer25): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1664, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(1664, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer26): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1696, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(1696, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer27): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(1728, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer28): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1760, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(1760, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer29): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(1792, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer30): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(1824, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer31): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1856, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(1856, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer32): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1888, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(1888, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (norm5): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (classifier): Linear(in_features=1920, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Printa modellen för att se de sista FC-lagren som behöver bytas ut: \n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_last_fc_infeatures = 1920\n",
    "model_name = 'Densenet201'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Densenet201_e100_bsztr4_bszval64_lr1e-04'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_filename(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_training == True:\n",
    "    \n",
    "    # Vi måste ändra på det sista FC-lagret i modellen, som från början\n",
    "    # innehållet 1000 st out-features. Vi behöver bara 7.\n",
    "\n",
    "    for param in model.parameters():\n",
    "        param.require_grad = False\n",
    "    \n",
    "    # Ersätt sista fc-lagret med rätt antal ut-klasser: \n",
    "    model.classifier = nn.Linear(in_features = models_last_fc_infeatures, out_features = number_of_classes, bias = True)\n",
    "    \n",
    "else:\n",
    "    model.classifier = nn.Linear(in_features = models_last_fc_infeatures, out_features = number_of_classes, bias = True)\n",
    "    load_trained_model(model_name)\n",
    "    model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flytta modellen till GPU, om en sådan finns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Flytta modellen till rätt device:\n",
    "\n",
    "to_device(model, device)\n",
    "\n",
    "# Verifiera att modellen är på rätt device:\n",
    "# True => modellen finns på GPU.\n",
    "\n",
    "next(model.parameters()).is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antalet träningsbara parametrar är 18,106,375 st.\n"
     ]
    }
   ],
   "source": [
    "trainableparameters = []\n",
    "for param in model.parameters():\n",
    "    # trainableparameters = param.numel()\n",
    "    trainableparameters.append(param.numel())\n",
    "    num_trainable_params = np.sum(trainableparameters)\n",
    "    \n",
    "print(f'Antalet träningsbara parametrar är {num_trainable_params:,} st.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definiera loss-function och vilken metod för optimering som ska användas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definiera loss-function och vilken optimerare som ska användas:\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decay LR by a factor of 0.1 every 3 epochs\n",
    "# exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size = 3, gamma = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Följande återställer modellens vikter mellan olika körningar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        torch.nn.init.xavier_uniform_(m.weight.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfit på en batch för att se att modellen är rimlig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_training == True:\n",
    "\n",
    "    model.apply(weights_init)\n",
    "    model.train()\n",
    "\n",
    "    inputs, labels = next(iter(train_dl_weighted))\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    criterion_check_onebatch = nn.CrossEntropyLoss()\n",
    "    optimizer_check_onebatch = optim.Adam(model.parameters(), lr = learning_rate)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(31):\n",
    "        optimizer_check_onebatch.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion_check_onebatch(outputs, labels)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss.backward()\n",
    "        optimizer_check_onebatch.step()\n",
    "        correct = torch.sum(preds == labels)\n",
    "    \n",
    "        if epoch%10 == 0:\n",
    "            print(f'Epok {epoch:02}: ----- loss = {loss:4.4f} ----- accuracy = {correct}')\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Träna och utvärdera modellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval(epochs = 10, do_validation = True, training_dataloader = train_dl_weighted, validation_dataloader = valid_dl):\n",
    "\n",
    "    # if ((do_training == False) and (do_validation == True)):\n",
    "    #    print(\"Kan inte validera en modell som inte tränats.\")\n",
    "    # else:\n",
    "    start_training_time = time.time()\n",
    "\n",
    "    # Placeholders för att mäta modellen:\n",
    "    global train_accuracy, train_losses, val_accuracy, val_losses\n",
    "        \n",
    "    train_accuracy = []\n",
    "    train_losses = []\n",
    "        \n",
    "    val_accuracy = []\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        start_epoch_time = time.time()\n",
    "        train_correct_pred_per_epoch = 0\n",
    "        \n",
    "        current_train_loss = 0.0\n",
    "        current_train_corrects = 0\n",
    "        \n",
    "        # Träning ###########################################################\n",
    "        # Sätt modellen i träningsläge:\n",
    "        start_train_time = time.time()\n",
    "        model.train()\n",
    "        \n",
    "        for inputs_train, labels_train in training_dataloader:\n",
    "            train_predictions = model.forward(inputs_train)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            train_loss = criterion(train_predictions, labels_train)\n",
    "            train_loss.backward()\n",
    "                \n",
    "            optimizer.step()\n",
    "                    \n",
    "            #exp_lr_scheduler.step()\n",
    "            #lr = exp_lr_scheduler.get_lr()\n",
    "                \n",
    "            # Nedan ger den mest troliga klassen:\n",
    "            _, train_predicted = torch.max(train_predictions, 1)\n",
    "    \n",
    "            current_train_loss += train_loss.item() * batchsz_train\n",
    "            current_train_corrects += torch.sum(train_predicted == labels_train.data)\n",
    "        \n",
    "        end_train_time = time.time()\n",
    "        \n",
    "        # Validering ########################################################\n",
    "        # Sätt modellen i utvärderingsläge:\n",
    "            \n",
    "        if do_validation == True:\n",
    "            start_eval_time = time.time()\n",
    "            model.eval()\n",
    "        \n",
    "            current_val_loss = 0.0\n",
    "            current_val_corrects = 0\n",
    "        \n",
    "            with torch.no_grad():\n",
    "                \n",
    "                inputs_val, labels_val = next(iter(validation_dataloader))\n",
    "                val_predictions = model.forward(inputs_val)\n",
    "                val_loss = criterion(val_predictions, labels_val)\n",
    "                _, val_predicted = torch.max(val_predictions, 1)\n",
    "                    \n",
    "                current_val_loss += val_loss.item() * batchsz_val\n",
    "                current_val_corrects += torch.sum(val_predicted == labels_val.data)\n",
    "        \n",
    "            end_eval_time = time.time()\n",
    "        else:\n",
    "            pass\n",
    "            \n",
    "        ######################################################################\n",
    "        \n",
    "        # Metrics ############################################################\n",
    "        # Räkna ut acc och loss per epok:\n",
    "        epoch_train_loss = np.float64(current_train_loss / num_train_images)\n",
    "        epoch_train_acc = np.float64(current_train_corrects.double() / num_train_images)\n",
    "        \n",
    "        if do_validation == True:\n",
    "            epoch_val_loss = np.float64(current_val_loss / batchsz_val)\n",
    "            epoch_val_acc = np.float64(current_val_corrects.double() / batchsz_val)\n",
    "        else:\n",
    "            pass\n",
    "                \n",
    "        # Lagra accuracy och loss per epok i en lista för t.ex. plottning:\n",
    "        train_losses.append(epoch_train_loss)\n",
    "        train_accuracy.append(epoch_train_acc)\n",
    "            \n",
    "        if do_validation == True:\n",
    "            val_losses.append(epoch_val_loss)\n",
    "            val_accuracy.append(epoch_val_acc)\n",
    "        else:\n",
    "            pass\n",
    "                \n",
    "        # Räkna ut tiderna per epok:\n",
    "        end_epoch_time = time.time()\n",
    "        epoch_time = end_epoch_time - start_epoch_time\n",
    "        \n",
    "        # epoch startar på 0, därav \"+1\" nedan:\n",
    "        if do_validation == True:\n",
    "            print(f\"Epok {epoch + 1:02}: {epoch_time:2.1f} sek, train-acc = {epoch_train_acc:4.3f}, val-acc = {epoch_val_acc:4.3f}, train-loss = {epoch_train_loss:4.4f}, val-loss = {epoch_val_loss:4.4f}\")            \n",
    "        else:\n",
    "            print(f\"Epok {epoch + 1:02}: {epoch_time:2.1f} sek, train-acc = {epoch_train_acc:4.3f}, train-loss = {epoch_train_loss:4.4f}\")\n",
    "    \n",
    "    # Spara träningsdatat i en fil och i en pandas-df:\n",
    "    save_training_log(model_name, do_validation)\n",
    "    \n",
    "    end_training_time = time.time()\n",
    "    \n",
    "    delta = end_training_time - start_training_time\n",
    "    \n",
    "    print(f'\\nTraining took {delta:.2f} seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Nollställer vikterna i modellen:\n",
    "if do_training == True:\n",
    "    model.apply(weights_init)\n",
    "else:\n",
    "    pass\n",
    "\n",
    "# Nedan för att vi använder \"droplast = True\"...\n",
    "\n",
    "# Train:\n",
    "num_train_images = batchsz_train * np.floor_divide(len(train_loader.dataset), batchsz_train)\n",
    "    \n",
    "# Validation:\n",
    "num_val_images = batchsz_val * np.floor_divide(len(valid_loader.dataset), batchsz_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Här görs själva träningen, valideringen, sparande av modellen och träningsloggen.\n",
    "# Alternativt så laddas en redan färdig modell/träningslogg.\n",
    "\n",
    "# \"epochs\" definieras i början av filen!\n",
    "\n",
    "if do_training == True:\n",
    "    train_eval(epochs, do_validation=True, training_dataloader=train_dl_weighted, validation_dataloader=valid_dl)\n",
    "    save_trained_model(model_name)\n",
    "else:\n",
    "    load_training_log(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rateg_rate = 1e-5\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epok 01: 414.6 sek, train-acc = 0.908, val-acc = 0.844, train-loss = 0.2584, val-loss = 0.6636\n",
      "Epok 02: 415.6 sek, train-acc = 0.922, val-acc = 0.672, train-loss = 0.2230, val-loss = 0.8658\n",
      "Epok 03: 415.6 sek, train-acc = 0.918, val-acc = 0.734, train-loss = 0.2335, val-loss = 0.5414\n",
      "Epok 04: 415.4 sek, train-acc = 0.928, val-acc = 0.766, train-loss = 0.2028, val-loss = 0.6017\n",
      "Epok 05: 415.5 sek, train-acc = 0.921, val-acc = 0.781, train-loss = 0.2228, val-loss = 1.0344\n",
      "Epok 06: 416.5 sek, train-acc = 0.923, val-acc = 0.844, train-loss = 0.2206, val-loss = 0.6010\n",
      "Epok 07: 415.0 sek, train-acc = 0.921, val-acc = 0.906, train-loss = 0.2212, val-loss = 0.2668\n",
      "Epok 08: 415.3 sek, train-acc = 0.928, val-acc = 0.672, train-loss = 0.2056, val-loss = 0.8191\n",
      "Epok 09: 416.0 sek, train-acc = 0.931, val-acc = 0.703, train-loss = 0.1974, val-loss = 0.7689\n",
      "Epok 10: 416.6 sek, train-acc = 0.927, val-acc = 0.844, train-loss = 0.1986, val-loss = 0.7411\n",
      "Epok 11: 416.8 sek, train-acc = 0.927, val-acc = 0.812, train-loss = 0.2101, val-loss = 0.4638\n",
      "Epok 12: 416.3 sek, train-acc = 0.930, val-acc = 0.797, train-loss = 0.2023, val-loss = 0.5922\n",
      "Epok 13: 416.3 sek, train-acc = 0.927, val-acc = 0.828, train-loss = 0.2051, val-loss = 0.4815\n",
      "Epok 14: 415.4 sek, train-acc = 0.931, val-acc = 0.828, train-loss = 0.2079, val-loss = 0.6249\n",
      "Epok 15: 416.7 sek, train-acc = 0.929, val-acc = 0.875, train-loss = 0.2003, val-loss = 0.4633\n",
      "Epok 16: 416.2 sek, train-acc = 0.926, val-acc = 0.734, train-loss = 0.2113, val-loss = 0.5853\n",
      "Epok 17: 416.8 sek, train-acc = 0.933, val-acc = 0.828, train-loss = 0.1868, val-loss = 0.4142\n",
      "Epok 18: 415.8 sek, train-acc = 0.939, val-acc = 0.750, train-loss = 0.1823, val-loss = 0.6580\n",
      "Epok 19: 416.0 sek, train-acc = 0.932, val-acc = 0.781, train-loss = 0.1919, val-loss = 0.8994\n",
      "Epok 20: 415.1 sek, train-acc = 0.933, val-acc = 0.828, train-loss = 0.2001, val-loss = 0.4709\n",
      "Epok 21: 416.2 sek, train-acc = 0.938, val-acc = 0.812, train-loss = 0.1818, val-loss = 0.5365\n",
      "Epok 22: 415.9 sek, train-acc = 0.937, val-acc = 0.750, train-loss = 0.1871, val-loss = 0.5582\n",
      "Epok 23: 416.3 sek, train-acc = 0.935, val-acc = 0.828, train-loss = 0.1851, val-loss = 0.6854\n",
      "Epok 24: 416.4 sek, train-acc = 0.932, val-acc = 0.781, train-loss = 0.1918, val-loss = 0.9376\n",
      "Epok 25: 416.0 sek, train-acc = 0.932, val-acc = 0.797, train-loss = 0.1945, val-loss = 0.7427\n",
      "Epok 26: 415.9 sek, train-acc = 0.940, val-acc = 0.797, train-loss = 0.1791, val-loss = 0.7619\n",
      "Epok 27: 415.4 sek, train-acc = 0.933, val-acc = 0.781, train-loss = 0.1906, val-loss = 0.5657\n",
      "Epok 28: 416.2 sek, train-acc = 0.932, val-acc = 0.891, train-loss = 0.1920, val-loss = 0.3761\n",
      "Epok 29: 416.2 sek, train-acc = 0.936, val-acc = 0.812, train-loss = 0.1855, val-loss = 0.7138\n",
      "Epok 30: 415.8 sek, train-acc = 0.939, val-acc = 0.734, train-loss = 0.1789, val-loss = 0.6370\n",
      "Epok 31: 415.9 sek, train-acc = 0.941, val-acc = 0.812, train-loss = 0.1738, val-loss = 0.5768\n",
      "Epok 32: 416.0 sek, train-acc = 0.940, val-acc = 0.797, train-loss = 0.1744, val-loss = 0.6142\n",
      "Epok 33: 416.5 sek, train-acc = 0.941, val-acc = 0.797, train-loss = 0.1714, val-loss = 0.5124\n",
      "Epok 34: 416.0 sek, train-acc = 0.938, val-acc = 0.656, train-loss = 0.1760, val-loss = 0.9271\n",
      "Epok 35: 416.1 sek, train-acc = 0.936, val-acc = 0.781, train-loss = 0.1792, val-loss = 1.0281\n",
      "Epok 36: 415.9 sek, train-acc = 0.943, val-acc = 0.797, train-loss = 0.1720, val-loss = 0.8610\n",
      "Epok 37: 416.8 sek, train-acc = 0.941, val-acc = 0.875, train-loss = 0.1649, val-loss = 0.6191\n",
      "Epok 38: 416.7 sek, train-acc = 0.938, val-acc = 0.766, train-loss = 0.1713, val-loss = 0.7030\n",
      "Epok 39: 416.4 sek, train-acc = 0.941, val-acc = 0.812, train-loss = 0.1722, val-loss = 0.5289\n",
      "Epok 40: 416.2 sek, train-acc = 0.939, val-acc = 0.750, train-loss = 0.1734, val-loss = 0.8776\n",
      "Epok 41: 417.0 sek, train-acc = 0.943, val-acc = 0.875, train-loss = 0.1676, val-loss = 0.6507\n",
      "Epok 42: 416.6 sek, train-acc = 0.941, val-acc = 0.812, train-loss = 0.1708, val-loss = 0.8725\n",
      "Epok 43: 416.4 sek, train-acc = 0.943, val-acc = 0.844, train-loss = 0.1711, val-loss = 0.6654\n",
      "Epok 44: 416.5 sek, train-acc = 0.940, val-acc = 0.797, train-loss = 0.1721, val-loss = 0.6541\n",
      "Epok 45: 415.4 sek, train-acc = 0.944, val-acc = 0.781, train-loss = 0.1631, val-loss = 0.8875\n",
      "Epok 46: 416.4 sek, train-acc = 0.944, val-acc = 0.891, train-loss = 0.1676, val-loss = 0.3151\n",
      "Epok 47: 416.3 sek, train-acc = 0.942, val-acc = 0.812, train-loss = 0.1646, val-loss = 0.6972\n",
      "Epok 48: 416.3 sek, train-acc = 0.942, val-acc = 0.859, train-loss = 0.1613, val-loss = 0.4408\n",
      "Epok 49: 416.2 sek, train-acc = 0.945, val-acc = 0.844, train-loss = 0.1579, val-loss = 0.4180\n",
      "Epok 50: 416.4 sek, train-acc = 0.943, val-acc = 0.828, train-loss = 0.1645, val-loss = 0.5050\n",
      "Epok 51: 416.5 sek, train-acc = 0.942, val-acc = 0.844, train-loss = 0.1618, val-loss = 0.4197\n",
      "Epok 52: 416.4 sek, train-acc = 0.945, val-acc = 0.750, train-loss = 0.1605, val-loss = 0.7296\n",
      "Epok 53: 415.8 sek, train-acc = 0.946, val-acc = 0.812, train-loss = 0.1551, val-loss = 0.6093\n",
      "Epok 54: 416.3 sek, train-acc = 0.944, val-acc = 0.734, train-loss = 0.1666, val-loss = 0.7867\n",
      "Epok 55: 416.4 sek, train-acc = 0.950, val-acc = 0.781, train-loss = 0.1496, val-loss = 0.8908\n",
      "Epok 56: 416.4 sek, train-acc = 0.949, val-acc = 0.781, train-loss = 0.1530, val-loss = 0.9427\n",
      "Epok 57: 416.1 sek, train-acc = 0.944, val-acc = 0.781, train-loss = 0.1595, val-loss = 0.9113\n",
      "Epok 58: 417.1 sek, train-acc = 0.945, val-acc = 0.734, train-loss = 0.1552, val-loss = 0.8834\n",
      "Epok 59: 415.0 sek, train-acc = 0.952, val-acc = 0.844, train-loss = 0.1493, val-loss = 1.0224\n",
      "Epok 60: 416.9 sek, train-acc = 0.945, val-acc = 0.781, train-loss = 0.1618, val-loss = 0.6676\n",
      "Epok 61: 415.9 sek, train-acc = 0.943, val-acc = 0.828, train-loss = 0.1628, val-loss = 0.7260\n",
      "Epok 62: 415.8 sek, train-acc = 0.952, val-acc = 0.750, train-loss = 0.1485, val-loss = 0.6432\n",
      "Epok 63: 416.2 sek, train-acc = 0.947, val-acc = 0.812, train-loss = 0.1554, val-loss = 0.8027\n",
      "Epok 64: 417.3 sek, train-acc = 0.946, val-acc = 0.812, train-loss = 0.1609, val-loss = 0.5429\n",
      "Epok 65: 416.2 sek, train-acc = 0.944, val-acc = 0.812, train-loss = 0.1600, val-loss = 0.8641\n",
      "Epok 66: 415.9 sek, train-acc = 0.945, val-acc = 0.766, train-loss = 0.1571, val-loss = 0.7975\n",
      "Epok 67: 417.1 sek, train-acc = 0.944, val-acc = 0.781, train-loss = 0.1621, val-loss = 1.0743\n",
      "Epok 68: 416.1 sek, train-acc = 0.951, val-acc = 0.797, train-loss = 0.1407, val-loss = 0.5382\n",
      "Epok 69: 414.4 sek, train-acc = 0.949, val-acc = 0.891, train-loss = 0.1467, val-loss = 0.3237\n",
      "Epok 70: 414.9 sek, train-acc = 0.949, val-acc = 0.797, train-loss = 0.1428, val-loss = 0.6113\n",
      "Epok 71: 415.3 sek, train-acc = 0.947, val-acc = 0.859, train-loss = 0.1503, val-loss = 0.6214\n",
      "Epok 72: 415.6 sek, train-acc = 0.947, val-acc = 0.859, train-loss = 0.1518, val-loss = 0.5186\n",
      "Epok 73: 415.9 sek, train-acc = 0.953, val-acc = 0.781, train-loss = 0.1415, val-loss = 0.6227\n",
      "Epok 74: 415.8 sek, train-acc = 0.942, val-acc = 0.734, train-loss = 0.1697, val-loss = 0.8755\n",
      "Epok 75: 416.1 sek, train-acc = 0.948, val-acc = 0.812, train-loss = 0.1425, val-loss = 0.5394\n",
      "Epok 76: 416.6 sek, train-acc = 0.950, val-acc = 0.875, train-loss = 0.1470, val-loss = 0.4905\n",
      "Epok 77: 416.7 sek, train-acc = 0.947, val-acc = 0.844, train-loss = 0.1480, val-loss = 0.5571\n",
      "Epok 78: 421.3 sek, train-acc = 0.951, val-acc = 0.828, train-loss = 0.1433, val-loss = 0.6666\n",
      "Epok 79: 421.4 sek, train-acc = 0.952, val-acc = 0.797, train-loss = 0.1310, val-loss = 0.7819\n",
      "Epok 80: 421.8 sek, train-acc = 0.949, val-acc = 0.766, train-loss = 0.1499, val-loss = 0.9193\n",
      "Epok 81: 441.3 sek, train-acc = 0.948, val-acc = 0.797, train-loss = 0.1484, val-loss = 0.8148\n",
      "Epok 82: 419.2 sek, train-acc = 0.949, val-acc = 0.828, train-loss = 0.1437, val-loss = 0.8570\n",
      "Epok 83: 420.4 sek, train-acc = 0.952, val-acc = 0.859, train-loss = 0.1408, val-loss = 0.3165\n",
      "Epok 84: 420.3 sek, train-acc = 0.950, val-acc = 0.812, train-loss = 0.1372, val-loss = 0.5300\n",
      "Epok 85: 419.5 sek, train-acc = 0.955, val-acc = 0.781, train-loss = 0.1342, val-loss = 1.0804\n",
      "Epok 86: 420.0 sek, train-acc = 0.953, val-acc = 0.828, train-loss = 0.1430, val-loss = 0.4527\n",
      "Epok 87: 419.6 sek, train-acc = 0.951, val-acc = 0.797, train-loss = 0.1349, val-loss = 0.9188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epok 88: 419.8 sek, train-acc = 0.949, val-acc = 0.828, train-loss = 0.1486, val-loss = 0.4344\n",
      "Epok 89: 419.0 sek, train-acc = 0.950, val-acc = 0.828, train-loss = 0.1455, val-loss = 0.4775\n",
      "Epok 90: 418.8 sek, train-acc = 0.953, val-acc = 0.812, train-loss = 0.1349, val-loss = 0.7577\n",
      "Epok 91: 419.4 sek, train-acc = 0.952, val-acc = 0.812, train-loss = 0.1353, val-loss = 0.6667\n",
      "Epok 92: 418.7 sek, train-acc = 0.949, val-acc = 0.812, train-loss = 0.1486, val-loss = 0.6669\n",
      "Epok 93: 419.4 sek, train-acc = 0.952, val-acc = 0.797, train-loss = 0.1377, val-loss = 0.7431\n",
      "Epok 94: 415.4 sek, train-acc = 0.948, val-acc = 0.750, train-loss = 0.1435, val-loss = 0.6411\n",
      "Epok 95: 416.3 sek, train-acc = 0.952, val-acc = 0.797, train-loss = 0.1386, val-loss = 0.6980\n",
      "Epok 96: 415.7 sek, train-acc = 0.951, val-acc = 0.875, train-loss = 0.1423, val-loss = 0.4967\n",
      "Epok 97: 416.0 sek, train-acc = 0.950, val-acc = 0.812, train-loss = 0.1425, val-loss = 1.0327\n",
      "Epok 98: 416.7 sek, train-acc = 0.949, val-acc = 0.766, train-loss = 0.1409, val-loss = 0.6464\n",
      "Epok 99: 417.4 sek, train-acc = 0.946, val-acc = 0.781, train-loss = 0.1489, val-loss = 0.8092\n",
      "Epok 100: 415.5 sek, train-acc = 0.953, val-acc = 0.844, train-loss = 0.1344, val-loss = 0.6794\n",
      "\n",
      "Training took 41691.45 seconds.\n"
     ]
    }
   ],
   "source": [
    "train_eval(epochs, do_validation=True, training_dataloader=train_dl_weighted, validation_dataloader=valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.908195</td>\n",
       "      <td>0.258442</td>\n",
       "      <td>0.843750</td>\n",
       "      <td>0.663605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.922045</td>\n",
       "      <td>0.223049</td>\n",
       "      <td>0.671875</td>\n",
       "      <td>0.865813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.918047</td>\n",
       "      <td>0.233455</td>\n",
       "      <td>0.734375</td>\n",
       "      <td>0.541371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.928469</td>\n",
       "      <td>0.202821</td>\n",
       "      <td>0.765625</td>\n",
       "      <td>0.601748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.921188</td>\n",
       "      <td>0.222847</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>1.034425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  train_acc  train_loss   val_acc  val_loss\n",
       "0      1   0.908195    0.258442  0.843750  0.663605\n",
       "1      2   0.922045    0.223049  0.671875  0.865813\n",
       "2      3   0.918047    0.233455  0.734375  0.541371\n",
       "3      4   0.928469    0.202821  0.765625  0.601748\n",
       "4      5   0.921188    0.222847  0.781250  1.034425"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_log.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utvärdering av modellen:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grafer över accuracy och loss på train/validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(training_log['epoch'], training_log['train_loss'])\n",
    "#plt.title(\"Loss on the training set over the epochs\")\n",
    "# plt.yticks(np.arange(0, 50, step = 5))\n",
    "# plt.ylim(0,50)\n",
    "#plt.show()\n",
    "\n",
    "# Plotta accuracy över valideringsdatat:\n",
    "plt.plot(training_log['epoch'], training_log['val_loss'])\n",
    "plt.title(\"Training and validation loss\")\n",
    "#plt.yticks(np.arange(0, 1.1, step = 0.2))\n",
    "#plt.ylim(0, max())\n",
    "plt.legend(['Train loss', 'Validation loss'], loc = 'upper right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(training_log['epoch'], training_log['train_acc'])\n",
    "#plt.title(\"Loss on the training set over the epochs\")\n",
    "# plt.yticks(np.arange(0, 50, step = 5))\n",
    "# plt.ylim(0,50)\n",
    "#plt.show()\n",
    "\n",
    "# Plotta accuracy över valideringsdatat:\n",
    "plt.plot(training_log['epoch'], training_log['val_acc'])\n",
    "plt.title(\"Training and validation accuracy\")\n",
    "#plt.yticks(np.arange(0, 1.1, step = 0.2))\n",
    "#plt.ylim(0, max())\n",
    "plt.legend(['Train acc', 'Validation acc'], loc = 'lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_train_acc = 100*max(training_log['train_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max tränings-accuracy = 88.86 %.\n"
     ]
    }
   ],
   "source": [
    "print(f'Max tränings-accuracy = {max_train_acc:.2f} %.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utvärdera modellen på validation- och test-set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(num_eval_images, data_loader, model):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    start_eval_test_time = time.time()\n",
    "    \n",
    "    # Nedan för att vi inte ska uppdatera \n",
    "    # modellens vikter:\n",
    "\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        # Antal iterationer = num_test_images / batchsz_test = x st.\n",
    "    \n",
    "        for X_test, y_test in data_loader:\n",
    "            y_pred_test = model.forward(X_test)\n",
    "            predicted = torch.max(input = y_pred_test, dim = 1)[1]\n",
    "            correct += (predicted == y_test).sum()\n",
    "    \n",
    "        end_eval_test_time = time.time()\n",
    "    \n",
    "        eval_test_time = end_eval_test_time - start_eval_test_time\n",
    "\n",
    "    print(f'Test accuracy: {correct.item()}/{num_eval_images} = {correct.item()*100/(num_eval_images):5.2f} %')\n",
    "    print(f\"\\nEvaluation took {eval_test_time:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/johanthor/anaconda3/envs/pytorch_general/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Users/johanthor/anaconda3/envs/pytorch_general/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Users/johanthor/anaconda3/envs/pytorch_general/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Users/johanthor/anaconda3/envs/pytorch_general/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-6b8b063e72e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnum_test_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_test_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-68-41a390e9c1aa>\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(num_eval_images, data_loader, model)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0my_pred_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_pred_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mcorrect\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_general/lib/python3.7/site-packages/torchvision/models/densenet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madaptive_avg_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_general/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_general/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_general/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_general/lib/python3.7/site-packages/torchvision/models/densenet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, init_features)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minit_features\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_children\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mnew_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_general/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_general/lib/python3.7/site-packages/torchvision/models/densenet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *prev_features)\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mbottleneck_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbn_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mprev_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0mbottleneck_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbn_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mprev_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0mnew_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbottleneck_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_rate\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_general/lib/python3.7/site-packages/torchvision/models/densenet.py\u001b[0m in \u001b[0;36mbn_function\u001b[0;34m(*inputs)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbn_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mconcated_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mbottleneck_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcated_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbottleneck_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_general/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_general/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_general/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mconv2d_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    340\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    341\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 342\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_test_images = len(test_loader.dataset)\n",
    "\n",
    "evaluate_model(num_test_images, test_dl, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_valid_images = len(valid_loader.dataset)\n",
    "\n",
    "evaluate_model(num_valid_images, valid_dl, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pytorch_confusion_matrix(num_classes, model, dataloader):\n",
    "    \n",
    "    confusion_matrix = torch.zeros(num_classes, num_classes)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, classes) in enumerate(dataloader):\n",
    "            inputs = inputs.to(device)\n",
    "            classes = classes.to(device)\n",
    "            \n",
    "            predictions = model.forward(inputs)\n",
    "            _, preds = torch.max(predictions, 1)\n",
    "            \n",
    "            for t, p in zip(classes.view(-1), preds.view(-1)):\n",
    "                confusion_matrix[t.long(), p.long()] += 1\n",
    "    \n",
    "    return confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beräkningen av CM tog 10.17.\n"
     ]
    }
   ],
   "source": [
    "# Beräkningen på test-setet tar ca. 10 sek.\n",
    "# på den stationära datorn med GPU med 4 workers, \n",
    "# och ca. 19 sek. med 8 workers.\n",
    "\n",
    "start_cm_time = time.time()\n",
    "cm_test = pytorch_confusion_matrix(number_of_classes, model, test_dl)\n",
    "\n",
    "end_cm_time = time.time()\n",
    "\n",
    "delta_cm_time = end_cm_time - start_cm_time\n",
    "\n",
    "print(f'Beräkningen av CM tog {delta_cm_time:.2f}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spara confusion matrix till en fil...\n",
    "\n",
    "cm_file_suffice = \".pt\"\n",
    "cm_filename = \"results/\" + file_name + cm_file_suffice\n",
    "torch.save(cm_test, cm_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ladda CM från en fil:\n",
    "\n",
    "cm_test = torch.load(cm_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_test_np = cm_test.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  42.   10.    9.    0.    5.    1.    0.]\n",
      " [   8.   77.    9.    2.    1.    6.    1.]\n",
      " [   7.    6.  146.    7.   16.   37.    2.]\n",
      " [   0.    1.    4.   16.    0.    3.    0.]\n",
      " [   2.    6.   16.    2.  131.   61.    5.]\n",
      " [   8.   24.   60.   36.   66. 1122.   26.]\n",
      " [   0.    0.    0.    0.    3.    4.   22.]]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "print(cm_test_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision och recall (precision & sensitivitet):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beräkna första radens summa:\n",
    "sum_row_one = np.sum(cm_test_np[:,0])\n",
    "\n",
    "# Då blir t.ex. precision för label 1:\n",
    "precision_label_one = cm_test_np[0][0].item() / sum_row_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision för label 1 = 0.627\n"
     ]
    }
   ],
   "source": [
    "print(f'Precision för label 1 = {precision_label_one:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall för label 1 = 0.627\n"
     ]
    }
   ],
   "source": [
    "# Motsvarande blir recall för label 1:\n",
    "\n",
    "sum_col_1 = np.sum(cm_test_np[0,:])\n",
    "recall_label_one = cm_test_np[0][0] / sum_col_1\n",
    "\n",
    "print(f'Recall för label 1 = {recall_label_one:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'akiec'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Få ut labels så här:\n",
    "test_loader.dataset.classes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision för respektive klass:\n",
      "akiec: 0.627\n",
      "bcc  : 0.621\n",
      "bkl  : 0.598\n",
      "df   : 0.254\n",
      "mel  : 0.590\n",
      "nv   : 0.909\n",
      "vasc : 0.393\n",
      "\n",
      "Recall för respektive klass:\n",
      "akiec: 0.627\n",
      "bcc  : 0.740\n",
      "bkl  : 0.661\n",
      "df   : 0.667\n",
      "mel  : 0.587\n",
      "nv   : 0.836\n",
      "vasc : 0.759\n"
     ]
    }
   ],
   "source": [
    "# Skapa en sammanställning över precision/recall för alla sju klasser.\n",
    "\n",
    "# Precision:\n",
    "\n",
    "print(\"Precision för respektive klass:\")\n",
    "for i in range(number_of_classes):\n",
    "    sum_row_i = np.sum(cm_test_np[:, i])\n",
    "    recall_i = cm_test_np[i,i] / sum_row_i\n",
    "    print(f'{test_loader.dataset.classes[i]:5}: {recall_i:.3f}')\n",
    "\n",
    "\n",
    "# Recall:\n",
    "\n",
    "print(\"\\nRecall för respektive klass:\")\n",
    "for j in range(number_of_classes):\n",
    "    sum_col_j = np.sum(cm_test_np[j, :])\n",
    "    recall_j = cm_test_np[j,j] / sum_col_j\n",
    "    print(f'{test_loader.dataset.classes[j]:5}: {recall_j:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisera modellens förutsägelser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_model(model, num_images = 6):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(test_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            for j in range(inputs.size()[0]):\n",
    "                images_so_far += 1\n",
    "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
    "                ax.axis('off')\n",
    "                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
    "                imshow(inputs.cpu().data[j])\n",
    "\n",
    "                if images_so_far == num_images:\n",
    "                    model.train(mode = was_training)\n",
    "                    return\n",
    "        model.train(mode = was_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_model(model, 4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_general",
   "language": "python",
   "name": "pytorch_general"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "526.726px",
    "left": "854.368px",
    "right": "20px",
    "top": "120px",
    "width": "421.087px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
