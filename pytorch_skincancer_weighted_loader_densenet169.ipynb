{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skincancer HAM-dataset med Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_training = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardimporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms, models\n",
    "from torchvision.utils import make_grid\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "import time\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hantering av GPU och CPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = get_default_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### De båda nedanstående blocken används för att enkelt flytta till GPU: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl: \n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hjälpfunktioner för att spara och ladda:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anropas när följande variabler finns tillgängliga:\n",
    "# epochs, batchsz-{train, val}, learning_rate\n",
    "# Dessa krävs för funktionen \"create_filename\".\n",
    "\n",
    "def create_filename(filename):\n",
    "    global file_name\n",
    "    file_name = filename + \"_e\" + str(epochs) + \"_bsztr\" + str(batchsz_train) + \\\n",
    "            \"_bszval\" + str(batchsz_val) + \"_lr\" + str(f'{learning_rate:.0e}')\n",
    "    return file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pytorch.org/docs/master/notes/serialization.html\n",
    "\n",
    "def save_trained_model(modelname):\n",
    "    model_folder = \"trained_models\"\n",
    "    model_file_suffix = \".pt\"\n",
    "    create_filename(modelname) # spottar ur sig ett filnamn i variabeln \"file_name\"\n",
    "    \n",
    "    full_model_filename = model_folder + \"/\" + file_name + model_file_suffix\n",
    "    \n",
    "    torch.save(model.state_dict(), full_model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_trained_model(modelname):\n",
    "    model_folder = \"trained_models\"\n",
    "    model_file_suffix = \".pt\"\n",
    "    create_filename(modelname) # spottar ur sig ett filnamn i variabeln \"file_name\"\n",
    "    \n",
    "    full_model_filename = model_folder + \"/\" + file_name + model_file_suffix\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        model.load_state_dict(torch.load(full_model_filename))\n",
    "    else:\n",
    "        model.load_state_dict(torch.load(full_model_filename, map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_training_log(logname, do_validation = True):\n",
    "    log_folder = \"logs\"\n",
    "    log_filename = create_filename(logname)\n",
    "    log_file_suffix = \".csv\"\n",
    "    full_log_filename = log_folder + \"/\" + file_name + log_file_suffix\n",
    "        \n",
    "    global training_log\n",
    "        \n",
    "    # Speciell range nedan för att starta på epok 1 och ej 0:\n",
    "    if do_validation == True:\n",
    "        training_log = pd.DataFrame(data={\"epoch\": range(1, epochs + 1), \\\n",
    "                                              \"train_acc\": train_accuracy, \\\n",
    "                                              \"train_loss\": train_losses,  \\\n",
    "                                              \"val_acc\": val_accuracy, \\\n",
    "                                              \"val_loss\": val_losses})\n",
    "    \n",
    "        training_log.to_csv(full_log_filename, sep=',', index = False)\n",
    "    else:\n",
    "        training_log = pd.DataFrame(data={\"epoch\": range(1, epochs + 1), \\\n",
    "                                              \"train_acc\": train_accuracy, \\\n",
    "                                              \"train_loss\": train_losses})\n",
    "    \n",
    "        training_log.to_csv(full_log_filename, sep=',', index = False)\n",
    "    \n",
    "    return training_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_training_log(logname):\n",
    "    log_folder = \"logs\"\n",
    "    log_filename = create_filename(logname)\n",
    "    log_file_suffix = \".csv\"\n",
    "    full_log_filename = log_folder + \"/\" + file_name + log_file_suffix\n",
    "    \n",
    "    global training_log\n",
    "    training_log = pd.read_csv(full_log_filename)\n",
    "    return training_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definiera de olika mängderna för träning, validering och test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "learning_rate = 1e-4\n",
    "\n",
    "img_w = 224\n",
    "img_h = 224\n",
    "img_dim = 3\n",
    "\n",
    "batchsz_train = 2**2\n",
    "batchsz_val = 2**6\n",
    "batchsz_test = 2**6\n",
    "\n",
    "train_num_workers = 4\n",
    "test_val_num_workers = 4\n",
    "\n",
    "basepath = \"../../../ml/Datasets/skin-cancer-mnist-ham10000/images_per_label_splitted_sets/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definiera vilken augmentation som ska göras:\n",
    "train_data_transform = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(img_w),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "val_test_data_transform = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(img_w),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definiera de tre dataseten:\n",
    "skincancer_train_dataset = datasets.ImageFolder(root = basepath + 'train/',\n",
    "                                           transform = train_data_transform)\n",
    "\n",
    "skincancer_valid_dataset = datasets.ImageFolder(root = basepath + 'val/',\n",
    "                                           transform = val_test_data_transform)\n",
    "\n",
    "skincancer_test_dataset = datasets.ImageFolder(root = basepath + 'test/',\n",
    "                                              transform = val_test_data_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skapa loaders för de tre dataseten:\n",
    "train_loader = torch.utils.data.DataLoader(skincancer_train_dataset,\n",
    "                                             batch_size = batchsz_train, \n",
    "                                             shuffle = True,\n",
    "                                             pin_memory = True,\n",
    "                                             drop_last = True,\n",
    "                                             num_workers = train_num_workers)\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(skincancer_valid_dataset,\n",
    "                                             batch_size = batchsz_val, \n",
    "                                             shuffle = True,\n",
    "                                             num_workers = test_val_num_workers)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(skincancer_test_dataset,\n",
    "                                             batch_size = batchsz_test, \n",
    "                                             shuffle = False,\n",
    "                                             num_workers = test_val_num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skapa en weighted loader som hanterar obalansen mellan klasserna:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_targets = train_loader.dataset.targets\n",
    "# print(len(train_targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import WeightedRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test för att oversampla vissa klasser...\n",
    "# https://discuss.pytorch.org/t/how-to-implement-oversampling-in-cifar-10/16964/6\n",
    "\n",
    "train_targets = train_loader.dataset.targets\n",
    "class_count = np.unique(train_targets, return_counts=True)[1]\n",
    "#print(\"Antal bilder per klass = \", class_count, \"\\n\")\n",
    "\n",
    "# Testa att köra med 1 / sevenones för att se en obalanserad, vanlig, loader\n",
    "# och med 1 / class_count för att se hur det balanserade resultatet blir:\n",
    "\n",
    "# sevenones = np.ones(7)\n",
    "# weight = 1 / sevenones\n",
    "weight = 1. / class_count\n",
    "samples_weight = weight[train_targets]\n",
    "samples_weight = torch.from_numpy(samples_weight)\n",
    "\n",
    "# Replacement = True ger dragning med återläggning, vilket vi ska ha, \n",
    "# annars kommer de mindre klasserna \"ta slut\" i dragningen:\n",
    "sampler = WeightedRandomSampler(samples_weight, len(samples_weight), replacement=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skapa en ny dataloader baserad på \n",
    "# träningssetet som är viktad klassivs:\n",
    "\n",
    "# \"pin_memory=True\" gör att man flyttar data till GPU:n medan \n",
    "# vi kör träningen, vilket påskyndar arbetet radikalt, ffa\n",
    "# om vi har komplexa modeller.\n",
    "train_loader_weighted = DataLoader(skincancer_train_dataset, \n",
    "                             batch_size = batchsz_train, \n",
    "                             sampler = sampler, # kan ej ha shuffle = True med sampler!\n",
    "                             pin_memory=True,\n",
    "                             drop_last=True,\n",
    "                             num_workers = train_num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definiera antalet klasser:\n",
    "\n",
    "number_of_classes = len(test_loader.dataset.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flytta *_loader till rätt device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DeviceDataLoader(train_loader, device)\n",
    "train_dl_weighted = DeviceDataLoader(train_loader_weighted, device)\n",
    "valid_dl = DeviceDataLoader(valid_loader, device)\n",
    "test_dl = DeviceDataLoader(test_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visa skillnader mellan oviktad och viktad loader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antal bilder per klass =  [ 228  359  769   80  779 4693   99] \n",
      "\n",
      "Batch 0, classes [2 5 6], count [1 1 2]\n",
      "Batch 1, classes [0 1 2 4], count [1 1 1 1]\n",
      "Batch 2, classes [1 3 6], count [1 2 1]\n",
      "Batch 3, classes [2 3 5], count [1 1 2]\n"
     ]
    }
   ],
   "source": [
    "print(\"Antal bilder per klass = \", class_count, \"\\n\")\n",
    "\n",
    "# Visa hur den drar samples från klasserna för fyra batcher:\n",
    "for batch_idx, (data, target) in enumerate(train_loader_weighted):\n",
    "    print('Batch {}, classes {}, count {}'.format(\n",
    "        batch_idx, *np.unique(target.numpy(), return_counts=True)))\n",
    "    if batch_idx == 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antal bilder per klass =  [ 228  359  769   80  779 4693   99] \n",
      "\n",
      "Batch 0, classes [2 4 5], count [1 1 2]\n",
      "Batch 1, classes [2 5], count [1 3]\n",
      "Batch 2, classes [1 2 5], count [2 1 1]\n",
      "Batch 3, classes [2 5], count [3 1]\n"
     ]
    }
   ],
   "source": [
    "print(\"Antal bilder per klass = \", class_count, \"\\n\")\n",
    "\n",
    "# Visa hur den drar samples från klasserna för fyra batcher:\n",
    "for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    print('Batch {}, classes {}, count {}'.format(\n",
    "        batch_idx, *np.unique(target.numpy(), return_counts=True)))\n",
    "    if batch_idx == 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(target) # ger en vektor med batchsz i storlek.\n",
    "\n",
    "# Kolla t.ex. hur många samples ur klass A som finns i sista batchen ovan:\n",
    "# A = 0\n",
    "# np.sum(target.numpy() == A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visa dimensionerna för en bild-tensor (batchsize, number of channels, width, height):\n",
    "# images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definiera en modell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nedanstående två rader måste göras oavsett träning eller ej:\n",
    "\n",
    "model = models.densenet169(pretrained = True, progress = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DenseNet(\n",
      "  (features): Sequential(\n",
      "    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu0): ReLU(inplace=True)\n",
      "    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (denseblock1): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (transition1): _Transition(\n",
      "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (denseblock2): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer7): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer8): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer9): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer10): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer11): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer12): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (transition2): _Transition(\n",
      "      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (denseblock3): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer7): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer8): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer9): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer10): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer11): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer12): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer13): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer14): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer15): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer16): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer17): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer18): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer19): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer20): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer21): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer22): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer23): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer24): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer25): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer26): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(1056, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer27): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1088, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer28): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(1120, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer29): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(1152, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer30): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(1184, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer31): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(1216, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer32): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(1248, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (transition3): _Transition(\n",
      "      (norm): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (denseblock4): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer7): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer8): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer9): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer10): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer11): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer12): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer13): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer14): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(1056, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer15): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1088, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer16): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(1120, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer17): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(1152, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer18): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(1184, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer19): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(1216, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer20): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(1248, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer21): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(1280, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer22): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1312, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(1312, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer23): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(1344, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer24): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1376, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(1376, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer25): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1408, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(1408, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer26): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(1440, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer27): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1472, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(1472, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer28): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1504, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(1504, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer29): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(1536, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer30): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1568, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(1568, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer31): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(1600, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer32): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(1632, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (norm5): BatchNorm2d(1664, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (classifier): Linear(in_features=1664, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Printa modellen för att se de sista FC-lagren som behöver bytas ut: \n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_last_fc_infeatures = 1664\n",
    "model_name = 'Densenet169'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Densenet169_e100_bsztr4_bszval64_lr1e-04'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_filename(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_training == True:\n",
    "    \n",
    "    # Vi måste ändra på det sista FC-lagret i modellen, som från början\n",
    "    # innehållet 1000 st out-features. Vi behöver bara 7.\n",
    "\n",
    "    for param in model.parameters():\n",
    "        param.require_grad = False\n",
    "    \n",
    "    # Ersätt sista fc-lagret med rätt antal ut-klasser: \n",
    "    model.classifier = nn.Linear(in_features = models_last_fc_infeatures, out_features = number_of_classes, bias = True)\n",
    "    \n",
    "else:\n",
    "    model.classifier = nn.Linear(in_features = models_last_fc_infeatures, out_features = number_of_classes, bias = True)\n",
    "    load_trained_model(model_name)\n",
    "    model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flytta modellen till GPU, om en sådan finns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Flytta modellen till rätt device:\n",
    "\n",
    "to_device(model, device)\n",
    "\n",
    "# Verifiera att modellen är på rätt device:\n",
    "# True => modellen finns på GPU.\n",
    "\n",
    "next(model.parameters()).is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antalet träningsbara parametrar är 12,496,135 st.\n"
     ]
    }
   ],
   "source": [
    "trainableparameters = []\n",
    "for param in model.parameters():\n",
    "    # trainableparameters = param.numel()\n",
    "    trainableparameters.append(param.numel())\n",
    "    num_trainable_params = np.sum(trainableparameters)\n",
    "    \n",
    "print(f'Antalet träningsbara parametrar är {num_trainable_params:,} st.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definiera loss-function och vilken metod för optimering som ska användas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definiera loss-function och vilken optimerare som ska användas:\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decay LR by a factor of 0.1 every 3 epochs\n",
    "# exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size = 3, gamma = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Följande återställer modellens vikter mellan olika körningar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        torch.nn.init.xavier_uniform_(m.weight.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfit på en batch för att se att modellen är rimlig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_training == True:\n",
    "\n",
    "    model.apply(weights_init)\n",
    "    model.train()\n",
    "\n",
    "    inputs, labels = next(iter(train_dl_weighted))\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    criterion_check_onebatch = nn.CrossEntropyLoss()\n",
    "    optimizer_check_onebatch = optim.Adam(model.parameters(), lr = learning_rate)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(31):\n",
    "        optimizer_check_onebatch.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion_check_onebatch(outputs, labels)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss.backward()\n",
    "        optimizer_check_onebatch.step()\n",
    "        correct = torch.sum(preds == labels)\n",
    "    \n",
    "        if epoch%10 == 0:\n",
    "            print(f'Epok {epoch:02}: ----- loss = {loss:4.4f} ----- accuracy = {correct}')\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Träna och utvärdera modellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval(epochs = 10, do_validation = True, training_dataloader = train_dl_weighted, validation_dataloader = valid_dl):\n",
    "\n",
    "    # if ((do_training == False) and (do_validation == True)):\n",
    "    #    print(\"Kan inte validera en modell som inte tränats.\")\n",
    "    # else:\n",
    "    start_training_time = time.time()\n",
    "\n",
    "    # Placeholders för att mäta modellen:\n",
    "    global train_accuracy, train_losses, val_accuracy, val_losses\n",
    "        \n",
    "    train_accuracy = []\n",
    "    train_losses = []\n",
    "        \n",
    "    val_accuracy = []\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        start_epoch_time = time.time()\n",
    "        train_correct_pred_per_epoch = 0\n",
    "        \n",
    "        current_train_loss = 0.0\n",
    "        current_train_corrects = 0\n",
    "        \n",
    "        # Träning ###########################################################\n",
    "        # Sätt modellen i träningsläge:\n",
    "        start_train_time = time.time()\n",
    "        model.train()\n",
    "        \n",
    "        for inputs_train, labels_train in training_dataloader:\n",
    "            train_predictions = model.forward(inputs_train)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            train_loss = criterion(train_predictions, labels_train)\n",
    "            train_loss.backward()\n",
    "                \n",
    "            optimizer.step()\n",
    "                    \n",
    "            #exp_lr_scheduler.step()\n",
    "            #lr = exp_lr_scheduler.get_lr()\n",
    "                \n",
    "            # Nedan ger den mest troliga klassen:\n",
    "            _, train_predicted = torch.max(train_predictions, 1)\n",
    "    \n",
    "            current_train_loss += train_loss.item() * batchsz_train\n",
    "            current_train_corrects += torch.sum(train_predicted == labels_train.data)\n",
    "        \n",
    "        end_train_time = time.time()\n",
    "        \n",
    "        # Validering ########################################################\n",
    "        # Sätt modellen i utvärderingsläge:\n",
    "            \n",
    "        if do_validation == True:\n",
    "            start_eval_time = time.time()\n",
    "            model.eval()\n",
    "        \n",
    "            current_val_loss = 0.0\n",
    "            current_val_corrects = 0\n",
    "        \n",
    "            with torch.no_grad():\n",
    "                \n",
    "                inputs_val, labels_val = next(iter(validation_dataloader))\n",
    "                val_predictions = model.forward(inputs_val)\n",
    "                val_loss = criterion(val_predictions, labels_val)\n",
    "                _, val_predicted = torch.max(val_predictions, 1)\n",
    "                    \n",
    "                current_val_loss += val_loss.item() * batchsz_val\n",
    "                current_val_corrects += torch.sum(val_predicted == labels_val.data)\n",
    "        \n",
    "            end_eval_time = time.time()\n",
    "        else:\n",
    "            pass\n",
    "            \n",
    "        ######################################################################\n",
    "        \n",
    "        # Metrics ############################################################\n",
    "        # Räkna ut acc och loss per epok:\n",
    "        epoch_train_loss = np.float64(current_train_loss / num_train_images)\n",
    "        epoch_train_acc = np.float64(current_train_corrects.double() / num_train_images)\n",
    "        \n",
    "        if do_validation == True:\n",
    "            epoch_val_loss = np.float64(current_val_loss / batchsz_val)\n",
    "            epoch_val_acc = np.float64(current_val_corrects.double() / batchsz_val)\n",
    "        else:\n",
    "            pass\n",
    "                \n",
    "        # Lagra accuracy och loss per epok i en lista för t.ex. plottning:\n",
    "        train_losses.append(epoch_train_loss)\n",
    "        train_accuracy.append(epoch_train_acc)\n",
    "            \n",
    "        if do_validation == True:\n",
    "            val_losses.append(epoch_val_loss)\n",
    "            val_accuracy.append(epoch_val_acc)\n",
    "        else:\n",
    "            pass\n",
    "                \n",
    "        # Räkna ut tiderna per epok:\n",
    "        end_epoch_time = time.time()\n",
    "        epoch_time = end_epoch_time - start_epoch_time\n",
    "        \n",
    "        # epoch startar på 0, därav \"+1\" nedan:\n",
    "        if do_validation == True:\n",
    "            print(f\"Epok {epoch + 1:02}: {epoch_time:2.1f} sek, train-acc = {epoch_train_acc:4.3f}, val-acc = {epoch_val_acc:4.3f}, train-loss = {epoch_train_loss:4.4f}, val-loss = {epoch_val_loss:4.4f}\")            \n",
    "        else:\n",
    "            print(f\"Epok {epoch + 1:02}: {epoch_time:2.1f} sek, train-acc = {epoch_train_acc:4.3f}, train-loss = {epoch_train_loss:4.4f}\")\n",
    "    \n",
    "    # Spara träningsdatat i en fil och i en pandas-df:\n",
    "    save_training_log(model_name, do_validation)\n",
    "    \n",
    "    end_training_time = time.time()\n",
    "    \n",
    "    delta = end_training_time - start_training_time\n",
    "    \n",
    "    print(f'\\nTraining took {delta:.2f} seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Nollställer vikterna i modellen:\n",
    "if do_training == True:\n",
    "    model.apply(weights_init)\n",
    "else:\n",
    "    pass\n",
    "\n",
    "# Nedan för att vi använder \"droplast = True\"...\n",
    "\n",
    "# Train:\n",
    "num_train_images = batchsz_train * np.floor_divide(len(train_loader.dataset), batchsz_train)\n",
    "    \n",
    "# Validation:\n",
    "num_val_images = batchsz_val * np.floor_divide(len(valid_loader.dataset), batchsz_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'logs/Densenet169_e100_bsztr4_bszval64_lr1e-04.csv' does not exist: b'logs/Densenet169_e100_bsztr4_bszval64_lr1e-04.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-c92b7c5e1607>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0msave_trained_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mload_training_log\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-12-f219338ac16b>\u001b[0m in \u001b[0;36mload_training_log\u001b[1;34m(logname)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mglobal\u001b[0m \u001b[0mtraining_log\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mtraining_log\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfull_log_filename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtraining_log\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pytorch_general\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    683\u001b[0m         )\n\u001b[0;32m    684\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pytorch_general\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pytorch_general\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pytorch_general\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1135\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1136\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pytorch_general\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1917\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File b'logs/Densenet169_e100_bsztr4_bszval64_lr1e-04.csv' does not exist: b'logs/Densenet169_e100_bsztr4_bszval64_lr1e-04.csv'"
     ]
    }
   ],
   "source": [
    "# Här görs själva träningen, valideringen, sparande av modellen och träningsloggen.\n",
    "# Alternativt så laddas en redan färdig modell/träningslogg.\n",
    "\n",
    "# \"epochs\" definieras i början av filen!\n",
    "\n",
    "if do_training == True:\n",
    "    train_eval(epochs, do_validation=True, training_dataloader=train_dl_weighted, validation_dataloader=valid_dl)\n",
    "    save_trained_model(model_name)\n",
    "else:\n",
    "    load_training_log(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.338806</td>\n",
       "      <td>1.675063</td>\n",
       "      <td>0.265625</td>\n",
       "      <td>3.8738</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  train_acc  train_loss   val_acc  val_loss\n",
       "0      1   0.338806    1.675063  0.265625    3.8738"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_log.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utvärdering av modellen:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grafer över accuracy och loss på train/validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(training_log['epoch'], training_log['train_loss'])\n",
    "#plt.title(\"Loss on the training set over the epochs\")\n",
    "# plt.yticks(np.arange(0, 50, step = 5))\n",
    "# plt.ylim(0,50)\n",
    "#plt.show()\n",
    "\n",
    "# Plotta accuracy över valideringsdatat:\n",
    "plt.plot(training_log['epoch'], training_log['val_loss'])\n",
    "plt.title(\"Training and validation loss\")\n",
    "#plt.yticks(np.arange(0, 1.1, step = 0.2))\n",
    "#plt.ylim(0, max())\n",
    "plt.legend(['Train loss', 'Validation loss'], loc = 'upper right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(training_log['epoch'], training_log['train_acc'])\n",
    "#plt.title(\"Loss on the training set over the epochs\")\n",
    "# plt.yticks(np.arange(0, 50, step = 5))\n",
    "# plt.ylim(0,50)\n",
    "#plt.show()\n",
    "\n",
    "# Plotta accuracy över valideringsdatat:\n",
    "plt.plot(training_log['epoch'], training_log['val_acc'])\n",
    "plt.title(\"Training and validation accuracy\")\n",
    "#plt.yticks(np.arange(0, 1.1, step = 0.2))\n",
    "#plt.ylim(0, max())\n",
    "plt.legend(['Train acc', 'Validation acc'], loc = 'lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_train_acc = 100*max(training_log['train_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max tränings-accuracy = 88.81 %.\n"
     ]
    }
   ],
   "source": [
    "print(f'Max tränings-accuracy = {max_train_acc:.2f} %.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utvärdera modellen på validation- och test-set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(num_eval_images, data_loader, model):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    start_eval_test_time = time.time()\n",
    "    \n",
    "    # Nedan för att vi inte ska uppdatera \n",
    "    # modellens vikter:\n",
    "\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        # Antal iterationer = num_test_images / batchsz_test = x st.\n",
    "    \n",
    "        for X_test, y_test in data_loader:\n",
    "            y_pred_test = model.forward(X_test)\n",
    "            predicted = torch.max(input = y_pred_test, dim = 1)[1]\n",
    "            correct += (predicted == y_test).sum()\n",
    "    \n",
    "        end_eval_test_time = time.time()\n",
    "    \n",
    "        eval_test_time = end_eval_test_time - start_eval_test_time\n",
    "\n",
    "    print(f'Test accuracy: {correct.item()}/{num_eval_images} = {correct.item()*100/(num_eval_images):5.2f} %')\n",
    "    print(f\"\\nEvaluation took {eval_test_time:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 1442/2010 = 71.74 %\n",
      "\n",
      "Evaluation took 8.27 seconds.\n"
     ]
    }
   ],
   "source": [
    "num_test_images = len(test_loader.dataset)\n",
    "\n",
    "evaluate_model(num_test_images, test_dl, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 749/998 = 75.05 %\n",
      "\n",
      "Evaluation took 4.61 seconds.\n"
     ]
    }
   ],
   "source": [
    "num_valid_images = len(valid_loader.dataset)\n",
    "\n",
    "evaluate_model(num_valid_images, valid_dl, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pytorch_confusion_matrix(num_classes, model, dataloader):\n",
    "    \n",
    "    confusion_matrix = torch.zeros(num_classes, num_classes)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, classes) in enumerate(dataloader):\n",
    "            inputs = inputs.to(device)\n",
    "            classes = classes.to(device)\n",
    "            \n",
    "            predictions = model.forward(inputs)\n",
    "            _, preds = torch.max(predictions, 1)\n",
    "            \n",
    "            for t, p in zip(classes.view(-1), preds.view(-1)):\n",
    "                confusion_matrix[t.long(), p.long()] += 1\n",
    "    \n",
    "    return confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beräkningen av CM tog 8.59.\n"
     ]
    }
   ],
   "source": [
    "# Beräkningen på test-setet tar ca. 24 sek.\n",
    "# på den stationära datorn med GPU med 4 workers, \n",
    "# och ca. 19 sek. med 8 workers.\n",
    "\n",
    "start_cm_time = time.time()\n",
    "cm_test = pytorch_confusion_matrix(number_of_classes, model, test_dl)\n",
    "\n",
    "end_cm_time = time.time()\n",
    "\n",
    "delta_cm_time = end_cm_time - start_cm_time\n",
    "\n",
    "print(f'Beräkningen av CM tog {delta_cm_time:.2f}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spara confusion matrix till en fil...\n",
    "\n",
    "cm_file_suffice = \".pt\"\n",
    "cm_filename = \"results/\" + file_name + cm_file_suffice\n",
    "torch.save(cm_test, cm_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ladda CM från en fil:\n",
    "\n",
    "cm_test = torch.load(cm_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_test_np = cm_test.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.800e+01, 1.900e+01, 4.000e+00, 0.000e+00, 3.000e+00, 2.000e+00,\n",
       "        1.000e+00],\n",
       "       [6.000e+00, 7.700e+01, 5.000e+00, 4.000e+00, 4.000e+00, 0.000e+00,\n",
       "        8.000e+00],\n",
       "       [1.200e+01, 1.300e+01, 1.250e+02, 1.200e+01, 2.500e+01, 3.100e+01,\n",
       "        3.000e+00],\n",
       "       [0.000e+00, 4.000e+00, 1.000e+00, 1.700e+01, 0.000e+00, 2.000e+00,\n",
       "        0.000e+00],\n",
       "       [6.000e+00, 1.100e+01, 2.500e+01, 0.000e+00, 1.400e+02, 3.800e+01,\n",
       "        3.000e+00],\n",
       "       [9.000e+00, 3.300e+01, 4.900e+01, 3.600e+01, 1.640e+02, 1.025e+03,\n",
       "        2.600e+01],\n",
       "       [0.000e+00, 2.000e+00, 0.000e+00, 0.000e+00, 1.000e+00, 2.000e+00,\n",
       "        2.400e+01]], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "print(cm_test_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision och recall (precision & sensitivitet):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beräkna första radens summa:\n",
    "sum_row_one = np.sum(cm_test_np[:,0])\n",
    "\n",
    "# Då blir t.ex. precision för label 1:\n",
    "precision_label_one = cm_test_np[0][0].item() / sum_row_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision för label 1 = 0.535\n"
     ]
    }
   ],
   "source": [
    "print(f'Precision för label 1 = {precision_label_one:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall för label 1 = 0.567\n"
     ]
    }
   ],
   "source": [
    "# Motsvarande blir recall för label 1:\n",
    "\n",
    "sum_col_1 = np.sum(cm_test_np[0,:])\n",
    "recall_label_one = cm_test_np[0][0] / sum_col_1\n",
    "\n",
    "print(f'Recall för label 1 = {recall_label_one:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'akiec'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Få ut labels så här:\n",
    "test_loader.dataset.classes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision för respektive klass:\n",
      "akiec: 0.535\n",
      "bcc  : 0.484\n",
      "bkl  : 0.598\n",
      "df   : 0.246\n",
      "mel  : 0.415\n",
      "nv   : 0.932\n",
      "vasc : 0.369\n",
      "\n",
      "Recall för respektive klass:\n",
      "akiec: 0.567\n",
      "bcc  : 0.740\n",
      "bkl  : 0.566\n",
      "df   : 0.708\n",
      "mel  : 0.628\n",
      "nv   : 0.764\n",
      "vasc : 0.828\n"
     ]
    }
   ],
   "source": [
    "# Skapa en sammanställning över precision/recall för alla sju klasser.\n",
    "\n",
    "# Precision:\n",
    "\n",
    "print(\"Precision för respektive klass:\")\n",
    "for i in range(number_of_classes):\n",
    "    sum_row_i = np.sum(cm_test_np[:, i])\n",
    "    recall_i = cm_test_np[i,i] / sum_row_i\n",
    "    print(f'{test_loader.dataset.classes[i]:5}: {recall_i:.3f}')\n",
    "\n",
    "\n",
    "# Recall:\n",
    "\n",
    "print(\"\\nRecall för respektive klass:\")\n",
    "for j in range(number_of_classes):\n",
    "    sum_col_j = np.sum(cm_test_np[j, :])\n",
    "    recall_j = cm_test_np[j,j] / sum_col_j\n",
    "    print(f'{test_loader.dataset.classes[j]:5}: {recall_j:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisera modellens förutsägelser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_model(model, num_images = 6):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(test_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            for j in range(inputs.size()[0]):\n",
    "                images_so_far += 1\n",
    "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
    "                ax.axis('off')\n",
    "                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
    "                imshow(inputs.cpu().data[j])\n",
    "\n",
    "                if images_so_far == num_images:\n",
    "                    model.train(mode = was_training)\n",
    "                    return\n",
    "        model.train(mode = was_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_model(model, 4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "526.726px",
    "left": "854.368px",
    "right": "20px",
    "top": "120px",
    "width": "421.087px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
